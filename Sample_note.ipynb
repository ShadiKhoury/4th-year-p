{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpretation (trian_data,test_data,trian_labels,test_labels,model,feature_imprtance_type=\"dice_local_cf\"):\n",
    "    #imports \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import math\n",
    "    import json\n",
    "    import plotly.graph_objs as go\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.metrics import plot_roc_curve\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn import preprocessing\n",
    "    from collections import Counter\n",
    "    import lightgbm as lgb\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.metrics import mean_squared_error,roc_auc_score,precision_score\n",
    "    pd.options.display.max_columns = 999\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    from itertools import cycle\n",
    "    plt.style.use('ggplot')\n",
    "    import dice_ml\n",
    "    from dice_ml.utils import helpers\n",
    "    from sklearn.metrics import precision_score, roc_auc_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score\n",
    "    # DiCE imports\n",
    "    import dice_ml\n",
    "    from dice_ml.utils import helpers\n",
    "    #########\n",
    "    #importing from CSV to Pandas\n",
    "    trian_data=pd.read_csv(\"%s\" % trian_data);\n",
    "    test_data=pd.read_csv(\"%s\"% test_data);\n",
    "    trian_labels=pd.read_csv(\"%s\"% trian_labels);\n",
    "    test_labels=pd.read_csv(\"%s\"% test_labels);\n",
    "\n",
    "    col_names=trian_data.columns;\n",
    "    # loop to change each column to float type\n",
    "    for col in col_names:\n",
    "        trian_data[col] = trian_data[col].astype('float',copy=False);\n",
    "        test_data[col]= test_data[col].astype('float',copy=False);\n",
    "    #selecting raws with no nan values\n",
    "    new_train=trian_data\n",
    "    new_train[\"Result\"]=trian_labels\n",
    "    new_test=test_data\n",
    "    new_test[\"Result\"]=test_labels\n",
    "    trian_data_nonull=new_train.dropna()\n",
    "    test_data_nonull=new_test.dropna()\n",
    "    trian_label_nonull=trian_data_nonull[\"Result\"]\n",
    "    test_label_nonull=test_data_nonull[\"Result\"]\n",
    "    trian_data_nonull.drop(labels = [\"Result\",], axis=1,inplace=True )\n",
    "    test_data_nonull.drop(labels = [\"Result\",], axis=1,inplace=True )\n",
    "    for col in col_names:\n",
    "        trian_data_nonull[col] = trian_data_nonull[col].astype('float',copy=False);\n",
    "        test_data_nonull[col]= test_data_nonull[col].astype('float',copy=False);\n",
    "    trian_data_nonull.reset_index(drop=True, inplace=True)\n",
    "    test_data_nonull.reset_index(drop=True, inplace=True)\n",
    "    #Scaling using the Standard Scaler\n",
    "    sc_1=StandardScaler();\n",
    "    X_1=pd.DataFrame(sc_1.fit_transform(trian_data_nonull));\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_1, trian_label_nonull, test_size=0.25, random_state=0) # 0.25 x 0.8 = 0\n",
    "    test_scale_data=pd.DataFrame(sc_1.fit_transform(test_data_nonull))\n",
    "    if model ==\"lgbm\": \n",
    "\n",
    "        #Bulding them Model\n",
    "        lgbm_clf = lgb.LGBMClassifier(\n",
    "        num_leaves= 20,\n",
    "        min_data_in_leaf= 4,\n",
    "        feature_fraction= 0.2,\n",
    "        bagging_fraction=0.8,\n",
    "        bagging_freq=5,\n",
    "        learning_rate= 0.05,\n",
    "        verbose=1,\n",
    "        num_boost_round=603,\n",
    "        early_stopping_rounds=5,\n",
    "        metric=\"auc\",\n",
    "        objective = 'binary',)\n",
    "\n",
    "        #Fitting the Model\n",
    "        lgbm_clf.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set = [(X_val, y_val)],\n",
    "            eval_metric=\"auc\",\n",
    "            )\n",
    "        preds = lgbm_clf.predict_proba(test_scale_data,num_iteration=100)\n",
    "        predict_model=lgbm_clf;\n",
    "    #dice local with cf\n",
    "    if feature_imprtance_type==\"dice_local_cf\":\n",
    "        trainn_data=trian_data_nonull;\n",
    "        trainn_data[\"labels\"]=trian_label_nonull\n",
    "        dicedata = dice_ml.Data(dataframe=trainn_data,continuous_features=[], outcome_name=\"labels\")\n",
    "        # Using sklearn backend\n",
    "        m = dice_ml.Model(model=predict_model, backend=\"sklearn\",model_type = 'classifier')\n",
    "        # Using method=random for generating CFs\n",
    "        exp_dice = dice_ml.Dice(dicedata, m, method=\"random\")\n",
    "        query_instance=test_data_nonull[4:5];\n",
    "        e1 = exp_dice.generate_counterfactuals(query_instance, total_CFs=10, \n",
    "                                       desired_class=\"opposite\",\n",
    "                                       verbose=False,\n",
    "                                       features_to_vary=\"all\")\n",
    "        #Local Feature Importance Scores with Counterfactuals list\n",
    "        imp = exp_dice.local_feature_importance(query_instance, cf_examples_list=e1.cf_examples_list);\n",
    "        result = imp.local_importance[0].items()\n",
    "        # Convert object to a list\n",
    "        data_imp = list(result);\n",
    "        feature_imp1 = pd.DataFrame(sorted(data_imp), columns=['Feature','Value'])\n",
    "        importance_df_dice_local_cf=feature_imp1\n",
    "        importance_df_dice_local_cf.columns = ['name', 'importance'];\n",
    "        importance_df_dice_local_cf = importance_df_dice_local_cf.sort_values('importance', ascending=False)\n",
    "        #Ploting\n",
    "        importance_df_dice_local_cf.plot.barh(y=\"importance\",x=\"name\",color=\"#FF6103\");\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"dice_local_cf_importance.pdf\")\n",
    "        #plt.show()\n",
    "        #js_dice_lc_cf = importance_df_dice_local_cf.to_json(orient = \"values\")\n",
    "        #parsed_3 = json.loads(js_dice_lc_cf)\n",
    "\n",
    "        #Json\n",
    "        importance_dict_dicecflo = importance_df_dice_local_cf.set_index('name').T.to_dict('records')[0]\n",
    "        with open('Dice_local_cf_Feature_Importance.json', 'w') as outfile:\n",
    "            return json.dump(importance_dict_dicecflo,outfile)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
